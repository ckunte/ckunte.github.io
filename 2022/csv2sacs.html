<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Chetan Kunté: CSV to SACS seastate</title>
<meta name="description" content="At work, we’ve been looking to determine cyclic axial capacity of a fixed platform’s drilled and...">
<script src="/inc/code-math.js" integrity="sha384-xT8wN8NCeuamUQtBjQWvwc7dCGAT89VKkZR5MVAcr18p99euBN7VZVb0NH07+lYA"></script>
<link rel="icon" href="/inc/favicon.svg" type="image/svg+xml">
<link type="text/css" rel="stylesheet" href="/inc/home.css">
</head>
<body>
<main>
<header>
  <a accesskey="/" title="Home" href="/"><img alt="Chetan Kunté" class="logo" src="/inc/favicon.svg" width="26" height="26"></a>
</header>	
<article>
<h1>CSV to SACS seastate</h1>
<time datetime="2022-11-10T22:20:00Z">10 Nov 2022</time>
<p>At work, we&rsquo;ve been looking to determine cyclic axial capacity of a fixed platform&rsquo;s drilled and grouted foundations in calcareous soils from storm time-history sets. The approach is described in a paper titled <a href="https://research-repository.uwa.edu.au/en/publications/axial-and-lateral-pile-design-in-carbonate-soils" title="C.T. Erbrich, et al., UWA, 2010.">Axial and lateral pile design in carbonate soils</a> by C.T. Erbrich, et al. (2010). The team is looking to generate pile loads from this using Bentley&rsquo;s SACS analysis suite. When totalled it adds to upwards of 30,000 discreet load cases.</p>
<p>With the archaic fixed-format, reminiscent of FORTRAN, SACS is unfriendly when it comes to developing user input files by hand, and in our case a seastate load input file. With 8,000 load cases, this requires generating about 127,000 unique lines of input, per history, error-free. Manually this is impractical.</p>
<p>I volunteered to find a way to automate this, if storm history were made available in comma separated value (CSV) files, which our Metocean team kindly did make. Last weekend, I rolled up sleeves and began coding in earnest in python, using <a href="https://pandas.pydata.org" title="A fast, powerful, flexible and easy to use open source data analysis and manipulation tool, built on top of the Python programming language.">pandas</a> dataframe structure, to turn thousands of lines of Metocean data into hundreds of thousands of ungodly SACS input. I am glad that I now have a working script that does this in a couple of seconds. The approach to generating input file is done in two steps:</p>
<ol>
<li>
<p>The Metocean data file structure (e.g. <code>TS001.000040TS.csv</code>) is as follows:</p>
<pre><code>H (m), T(s), ThetaP PlatformNth(Deg), WS (m/s), CS5(m/s),  CS20(m/s),  CS30(m/s),  CS50(m/s),    CS70(m/s),  CS90(m/s), CS110(m/s), CS130(m/s), CS150(m/s), CS170(m/s),
  4.48,  14.56,290.00,  13.84,  0.75,   0.68,  0.60,   0.50,  0.44,   0.41,  0.35,   0.30,  0.25,   0.15,
  4.81,  14.67,290.00,  13.84,  0.75,   0.68,  0.60,   0.50,  0.44,   0.41,  0.35,   0.30,  0.25,   0.15,
  4.40,  14.21,290.00,  13.84,  0.75,   0.68,  0.60,   0.50,  0.44,   0.41,  0.35,   0.30,  0.25,   0.15,
  4.18,  12.34,290.00,  13.84,  0.75,   0.68,  0.60,   0.50,  0.44,   0.41,  0.35,   0.30,  0.25,   0.15,
  2.83,   8.32,290.00,  13.84,  0.75,   0.68,  0.60,   0.50,  0.44,   0.41,  0.35,   0.30,  0.25,   0.15,
  3.76,  14.89,290.00,  13.84,  0.75,   0.68,  0.60,   0.50,  0.44,   0.41,  0.35,   0.30,  0.25,   0.15,
  6.07,  14.04,290.00,  13.84,  0.75,   0.68,  0.60,   0.50,  0.44,   0.41,  0.35,   0.30,  0.25,   0.15,
...
</code></pre>
<p>Read Metocean data file in CSV, and save it as a formatted CSV file using Pandas. This streamlines the CSV file:</p>
<pre><code>python3 fdf.py -f &lt;metocean data file&gt;
</code></pre>
</li>
<li>
<p>Step 1 above generates a formatted Metocean data file, which is used to generate SACS seastate input file:</p>
<pre><code>python3 slc.py -f &lt;formatted metocean data file&gt; &gt; seastate1.inp
</code></pre>
</li>
</ol>
<p>The script generates this <code>seastate1.inp</code> file &mdash; listed for brevity:</p>
<pre><code># Reading FTS001.000040TS.csv file...done.
FILE B
LOADCN   1
LOADLB   1Envir for pile storm analysis
WAVE
WAVE0.95STOK  4.48       14.56         290.0      D  -90.0   4.0  90MM10 1
CURR
CURR        1.18    0.15   290.0                        BC NL         AWP
CURR       21.18    0.25   290.0
CURR       41.18     0.3   290.0
CURR       61.18    0.35   290.0
CURR       81.18    0.41   290.0
CURR      101.18    0.44   290.0
CURR      121.18     0.5   290.0
CURR      141.18     0.6   290.0
CURR      151.18    0.68   290.0
CURR      166.18    0.75   290.0
LOADCN   2
LOADLB   2Envir for pile storm analysis
WAVE
WAVE0.95STOK  4.81       14.67         290.0      D  -90.0   4.0  90MM10 1
CURR
CURR        1.18    0.15   290.0                        BC NL         AWP
CURR       21.18    0.25   290.0
...
...
LOADCN7931
LOADLB7931Envir for pile storm analysis
WAVE
WAVE0.95STOK  6.63       11.36         185.0      D  -90.0   4.0  90MM10 1
CURR
CURR        1.18    0.17   185.0                        BC NL         AWP
CURR       21.18    0.28   185.0
CURR       41.18    0.33   185.0
CURR       61.18    0.39   185.0
CURR       81.18    0.45   185.0
CURR      101.18    0.48   185.0
CURR      121.18    0.55   185.0
CURR      141.18    0.67   185.0
CURR      151.18    0.75   185.0
CURR      166.18    0.83   185.0
</code></pre>
<p>It is important to have the Metocean data per CSV file to be less than or equal to 9999 load cases, since SACS has room for only as many (four character wide) in order to have numbered load conditions and labels without a counter-reset, or the need for extra code to add new counters, say, alpha-numeric types.</p>
<p><strong>Requirements:</strong> Both the scripts listed below require python3 with pandas and docopt modules. The modules can be installed with the following at command line:</p>
<pre><code class="language-bash">python3 -m pip install --upgrade pandas docopt
</code></pre>
<details>
<summary>Script to format Metocean data</summary>


<pre><code class="language-python">#!/usr/bin/env python3
# -*- coding: utf-8 -*-

&quot;&quot;&quot;Format CSV file with Pandas
fdf.py 2022 ckunte

Usage: fdf.py (-f &lt;file&gt;)
       fdf.py --help
       fdf.py --version

Options:
  -h, --help  Show this help
  -f --file   Specify CSV input file to format (required)

&quot;&quot;&quot;
import pandas as pd
from docopt import docopt


def main(*args):
    print(&quot;# Reading &quot; + datfile + &quot; file...&quot;, end=&quot;&quot;)
    df = pd.read_csv(&quot;./&quot; + datfile)
    print(&quot;done.&quot;)
    # remove wind speed column from data (by index -- this is a workaround:
    # [should be [3], but somehow [2] works -- possibly a python 3.8.10 bug)
    df2 = df.drop(df.columns[[2]], axis=1)
    return df2.to_csv(&quot;F&quot; + datfile)


if __name__ == &quot;__main__&quot;:
    args = docopt(
        __doc__, version=&quot;Generate SACS storm load cards from a CSV file, v0.1&quot;
    )
    datfile = &quot;%s&quot; % (args[&quot;&lt;file&gt;&quot;])
    main(datfile)
    print(&quot;Formatted file:&quot;, &quot;F&quot; + datfile)
</code></pre>

</details>

<p>Here&rsquo;s how <code>fdf.py</code> script works:</p>
<ol>
<li>Reads the CSV file (given at command line) into dataframe (<code>df</code>)</li>
<li>Returns a CSV file from dataframe with and <code>F</code> prefixed to the filename</li>
</ol>
<p>If one has many files that need formatting with the above script, then this can be done in one go with the following command:</p>
<pre><code class="language-bash">for FILE in *.csv; do python3 ./fdf.py -f $FILE; done
</code></pre>
<details>
<summary>Script to convert Metocean data (in CSV) into SACS seastate input</summary>


<pre><code class="language-python">#!/usr/bin/env python3
# -*- coding: utf-8 -*-

&quot;&quot;&quot;Generate SACS storm load cards from a CSV file
slc.py 2022 ckunte

Tested for python v3.8.10, v3.10.8 with pandas &gt;= v1.5.1

Usage: slc.py (-f &lt;file&gt;)
       slc.py --help
       slc.py --version

Options:
  -h, --help  Show this help
  -f --file   Specify CSV input file (required)

&quot;&quot;&quot;
import pandas as pd
from docopt import docopt


def main(*args):
    print(&quot;# Reading &quot; + datfile + &quot; file...&quot;, end=&quot;&quot;)
    df = pd.read_csv(&quot;./&quot; + datfile)
    print(&quot;done.&quot;)
    print(&quot;FILE B&quot;)
    for i in range(len(df)):
        # PRINTING WAVE INPUT LINES
        print(f&quot;LOADCN{i+1:4}&quot;)
        print(f&quot;LOADLB{i+1:4}Envir for pile storm analysis&quot;)
        print(W[0])
        print(
            f&quot;{W[0]:4}&quot;  # col 1-4, line label
            + f&quot;{W[1]:4}&quot;  # col 5-8, kinematics fac.
            + f&quot;{W[2]:4}&quot;  # col 9-12, wave type
            + f&quot;{df.iat[i, 0]:&gt;6}&quot;  # col 13-18, wave height
            + f&quot;{F[0]:&gt;6}&quot;  # col 19-24, SWL, skip (from LDOPT)
            + f&quot;{df.iat[i, 1]:&gt;6}&quot;  # col 25-30, wave period
            + f&quot;{F[0]:&gt;8}&quot;  # col 31-38, wave length, skip if period is given
            + f&quot;{df.iat[i, 2]:&gt;6}&quot;  # col 39-44, wave angle
            + f&quot;{F[0]:&gt;6}&quot;  # col 45-50, mud line elev., skip (from LDOPT)
            + f&quot;{W[3]:&gt;0}&quot;  # col 51, input mode
            + f&quot;{W[4]:&gt;7}&quot;  # col 52-58, crest position
            + f&quot;{W[5]:&gt;6}&quot;  # col 59-64, step size
            + f&quot;{F[0]:1}&quot;  # col 65-66, steps for dyn. analysis, skip
            + f&quot;{W[6]:1}&quot;  # col 67-68, static steps
            + f&quot;{W[7]:1}&quot;  # col 69-70, critical position
            + f&quot;{W[8]:1}&quot;  # col 71-72, member seg. (max)
            + f&quot;{W[9]:1}&quot;  # col 73-74, member seg. (min)
            # + &quot;{0:0}&quot;.format(F[0])  # col 75, local accel. only, skip
            # + &quot;{0:0}&quot;.format(F[0])  # col 76, print opt, skip
            # + &quot;{0:&lt;1}&quot;.format(F[0])  # col 77-78, order of stream func., skip
        )
        # PRINTING CURRENT INPUT LINES
        print(C[0])
        print(
            f&quot;{C[0]:4}&quot;  # col 1-4, line label
            + f&quot;{F[0]:&gt;4}&quot;  # col 5-8, min inline curr velocity, skip
            + f&quot;{eam[9]:&gt;8}&quot;  # col 9-16, elev above mud line
            + f&quot;{df.iat[i, 12]:&gt;8}&quot;  # col 17-24, curr velocity
            + f&quot;{df.iat[i, 2]:&gt;8}&quot;  # col 25-32, curr dir
            + f&quot;{F[0]:&gt;8}&quot;  # col 33-40, mudline elev override, skip
            + f&quot;{F[0]:&gt;8}&quot;  # col 41-48, blocking factor, skip
            + f&quot;{F[0]:&gt;8}&quot;  # col 49-56, elev, skip
            + f&quot;{C[1]:1}&quot;  # col 57-58, elev, generate blocking fac.
            + f&quot;{F[0]:&gt;0}&quot;  # col 59, null
            + f&quot;{C[2]:1}&quot;  # col 60-61, crest stretching opt.
            + f&quot;{F[0]:&gt;0}&quot;  # col 62, null
            + f&quot;{F[0]:2}&quot;  # col 63-65, velocity units opt., skip
            + f&quot;{F[0]:&gt;0}&quot;  # col 66, null
            + f&quot;{F[0]:2}&quot;  # col 67-69, elev percent opt., skip
            + f&quot;{F[0]:&gt;3}&quot;  # col 70, null (for now this is a workaround)
            + f&quot;{C[3]:&gt;2}&quot;  # col 71-73, AWP opt.
        )
        # adjust ranges depending upon the current profile
        for n, m in zip(range(8, -1, -1), range(11, 2, -1)):
            print(
                f&quot;{C[0]}&quot;  # col 1-4, line label
                + f&quot;{F[0]:&gt;4}&quot;  # col 5-8, min inline curr velocity, skip
                + f&quot;{eam[n]:&gt;8}&quot;  # col 9-16, elev above mud line
                + f&quot;{df.iat[i, m]:&gt;8}&quot;  # col 17-24, curr velocity
                + f&quot;{df.iat[i, 2]:&gt;8}&quot;  # col 25-32, curr dir
            )
    pass


if __name__ == &quot;__main__&quot;:
    args = docopt(
        __doc__, version=&quot;Generate SACS storm load cards from a CSV file, v0.1&quot;
    )
    datfile = &quot;%s&quot; % (args[&quot;&lt;file&gt;&quot;])
    #
    # -- BEGIN USER INPUTS --
    #
    # WAVE DEFINITION AND POSITION PARAMETERS (SACS SEASTATE MANUAL, PG 170)
    #
    W = [
        &quot;WAVE&quot;,  # line label
        0.95,  # kinematics factor
        &quot;STOK&quot;,  # wave type
        &quot;D&quot;,  # input mode (length (L), degree (D), or time (T))
        -90.0,  # crest position -- wave
        4.00,  # step size -- wave
        &quot; 90&quot;,  # static steps -- wave
        &quot;MM&quot;,  # critical position -- wave
        &quot;10&quot;,  # member segmentation (max)
        &quot; 1&quot;,  # member segmentation (min)
    ]
    # CURRENT PARAMETERS (SACS SEASTATE MANUAL, PG 171)
    #
    C = [
        &quot;CURR&quot;,  # line label
        &quot;BC&quot;,  # option to generate blocking factor
        &quot;NL&quot;,  # crest stretching option
        &quot;AWP&quot;,  # apparent wave period option
    ]
    # ELEVATION ABOVE MUDLINE (FOR CURRENT PROFILE)
    #
    eam = [
        166.18,
        151.18,
        141.18,
        121.18,
        101.18,
        81.18,
        61.18,
        41.18,
        21.18,
        1.18,
    ]
    # FILLER FOR EMPTY (OR NULL) COLUMN BLOCKS
    #
    F = [&quot; &quot;]
    #
    # CSV DATA FILE FROM METOCEAN TO USE
    #
    # Headers in CSV file:
    # H (m), T(s), ThetaP PltfNth(deg), WS (m/s), CS5(m/s),  CS20(m/s),  CS30(m/s),  CS50(m/s),  CS70(m/s),  CS90(m/s), CS110(m/s), CS130(m/s), CS150(m/s), CS170(m/s)

    # -- END USER INPUTS --

    main(datfile, W, F, C)
</code></pre>

</details>

<p>For a bunch of formatted files, SACS seastate input files can be generated in one go like so:</p>
<pre><code class="language-bash">for FILE in F*.csv; do python3 ./slc.py -f $FILE &gt; $FILE.inp; done
</code></pre>
<p>This script is specific to the structure of the CSV file and the order in which data parameters occur. The first three columns represent wave data (height, period, and direction), and the last ten columns (to be aligned with <code>eam</code> list) represent current speed at ten intervals from water surface to seabed in decreasing order. However, SACS requires this to be input in the increasing order, and therefore the ranges are reversed (aligned with <code>eam</code>) and in negative increments to get appropriate column indices. Other than that, this script just re-prints data from the dataframe in a fixed format that SACS requires. Here&rsquo;s how it works:</p>
<ol>
<li>Loads data from CSV file into a dataframe</li>
<li>Prints a line <code>FILE B</code> for a stand-alone seastate file</li>
<li>Begins a loop for all lines in the CSV file</li>
<li>Prints <code>WAVE</code> cards from wave data in the first 3 columns</li>
<li>Prints <code>CURR</code> cards (incl. multiline loop) from current data</li>
</ol>
<p>There is of course an opportunity to make this script generic (e.g., by updating it to automatically count columns from either side and generate column index accordingly for further use) so that there is no need to re-factor the code &mdash; should the data structure change, but this code solved our immediate problem.</p>
</article>
<footer>
    <span>
      &lsaquo; 
      <a accesskey="j" title="Slice lists" href="/2022/slice">
        Prev
      </a>
    </span>
    <span>
      <a accesskey="k" title="Build" href="/2024/build">
        Next
      </a> &rsaquo;
    </span>
  </footer></main>
</body>
</html>